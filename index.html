<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>University of Pittsburgh NLP Seminar</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="" />
<meta name="author" content="http://webthemez.com" />
<!-- css -->
<link href="css/bootstrap.min.css" rel="stylesheet" />
<link href="css/fancybox/jquery.fancybox.css" rel="stylesheet">
<link href="css/jcarousel.css" rel="stylesheet" />
<link href="css/flexslider.css" rel="stylesheet" />
<link href="js/owl-carousel/owl.carousel.css" rel="stylesheet">
<link href="css/style.css" rel="stylesheet" />

<!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
<!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

</head>
<body>
<div id="wrapper">
	<!-- start header -->
	<header>
	    <div class="container">
		 <a class="text-center" href="index.html">
       <img src="img/University_of_Pittsburgh_Logo_RGB_Primary_3-Color.png" alt="logo" style="width:25%;height:auto;padding-bottom:10px;margin-bottom:10px;margin-top:10px;margin-right:50px"/>
		  </a>
      <strong style="font-size:16pt;margin-left:10%">Natural Language Processing Seminar</strong>
	    </div>
	</header>
	<!-- end header -->
	<section id="inner-headline">
	</section>

	<section id="content">


	<div class="container" >

		<div class="skill-home">
		<div class="skill-home-solid clearfix" >
			<div style="text-align:center;font-size:16pt;font-weight:bold">
				This Week's Speaker
			</div>
			<hr>
			<hr>
			<div class="row">
			<div class="col-md-12 text-left">
				<div class="speaker-pic" style="display: inline-block">
					<img src="https://jmhessel.com/main_photo.jpg">
				</div>
				<div>
				<h3> Jack Hessel </h3>
				<p><b> AI2 </b></p>
				<p><b> Time:</b> 11/24/2020</p>
				<p><b> Place:</b> Zoom</p>
				<p><b> Title:</b> (at least) Two Conceptions of Visual-Textual Grounding</p>
				<p><b> Topic:</b> Multimodal Communication </p>
				<p><b>Abstract:</b> Algorithms that learn connections between visual and textual content underlie many important applications of AI, e.g., image captioning, robot navigation, and web video parsing. But what does it really mean for images and text to be "connected"? I'll discuss (at least) two orthogonal conceptions of visual-textual grounding. The first is operational grounding: if an algorithm can learn a consistent relationship between two data modalities based on co-occurrence data, then such a pattern can be called "grounded;" I'll discuss our work that applies this notion to both static images and to web videos. The second, more general view describes visual-textual grounding as a subset of "interesting" logical functions that take as input visual and textual variables. Under this paradigm, we design a diagnostic that can tell you if your multimodal model is doing cross-modal reasoning, or (as we find is the common case) exploiting single modal biases.</p>
				<p><b>Bio:</b> Jack is a postdoc at AI2, and earned a PhD in Computer Science at Cornell University. His work focuses on analyzing user-generated web content, and has been published at EMNLP, NAACL, WWW, etc. Previously, he's worked at Google, Facebook, and Twitter, and held an invited visiting faculty position in Computer Science at Carleton College.</p>
				</div>
			</div>
			</div>

			<hr>
			<hr>
			<div style="text-align:center;font-size:16pt;font-weight:bold">
				Previous Speakers
			</div>
			<hr>
			<hr>
			<div class="row">
			<div class="col-md-12 text-left">
				<!--<div class="col-md-4 offset-md-8" >-->
					<div class="speaker-pic" style="display: inline-block">
						<img src="https://people.ischool.berkeley.edu/~dbamman/bamman_pic_large.jpg">
					</div>
				<!--</div>-->
				<div>
				<h3> David Bamman</h3>
				<p><b> University of California, Berkeley </b></p>
				<p><b> Time:</b> 10/13/2020, Tuesday from 3 to 4 pm</p>
				<p><b> Place:</b> Zoom </p>
				<p><b> Title:</b> Modeling the Spread of Information within Novels </p>
				<p><b> Topic:</b> Language Generation </p>
				<p><b> Abstract:</b> Understanding the ways in which information flows through social networks is important for questions of influence--including tracking the spread of cultural trends and disinformation and measuring shifts in public opinion.  Much work in this space has focused on networks where nodes, edges and information are all directly observed (such as Twitter accounts with explicit friend/follower edges and retweets as instances of propagation); in this talk, I will focus on 	the comparatively overlooked case of information propagation in *implicit* networks--where we seek to discover single instances of a message passing from person A to person B to person C, only given a depiction of their activity in text. </p>
				<p>	Literature in many ways presents an ideal domain for modeling information propagation described in text, since it depicts a largely closed universe in which characters interact and speak to each other.  At the same time, it poses several wholly distinct challenges--in particular, both the length of literary texts and the subtleties involved in extracting information from fictional works pose difficulties for NLP systems optimized for other domains.  In this talk, I will describe our work in measuring information propagation in these implicit networks, and detail an NLP pipeline for discovering it, focusing in detail on new datasets we have created for tagging characters and their coreference in text.  This is joint work with Matt Sims, Olivia Lewke, Anya Mansoor, Sejal Popat and Sheng Shen. </p>
				<p><b> Bio:</b> David Bamman is an assistant professor in the School of Information at UC Berkeley, where he works in the areas of natural language processing and cultural analytics, applying NLP and machine learning to empirical questions in the humanities and social sciences. His research focuses on improving the performance of NLP for underserved domains like literature (including LitBank and BookNLP) and exploring the affordances of empirical methods for the study of literature and culture. Before Berkeley, he received his PhD in the School of Computer Science at Carnegie Mellon University and was a senior researcher at the Perseus Project of Tufts University. Bamman's work is supported by the National Endowment for the Humanities, National Science Foundation, an Amazon Research Award, and an NSF CAREER award. </p>
				<p><b> Slides: </b><a href="slides/pitt_nlp.pdf">Download </a></p>
				</div>
			</div>
		</div>

		<hr>

			<div class="row">

			<div class="col-md-12 text-left">
				<div class="speaker-pic" style="display: inline-block">
					<img src="https://cocoxu.github.io/files/weixu_profile.png">
				</div>

				<div class="speaker-pic" style="display: inline-block">
				</div>
				<div>
				<h3> Wei Xu </h3>
				<p><b> Georgia Institute of Technology</b></p>
				<p><b> Time:</b> 10/27/2020, Tuesday from 3 to 4 pm </p>
				<p><b> Place:</b> Zoom </p>
				<p><b> Title:</b> Automatic Text Simplification for K-12 Students </p>
				<p><b> Topic:</b> Language Generation </p>
				<p><b> Abstract:</b> Reading and writing are fundamental to the learning experience of students. In this talk, I will first exemplify how professional editors rewrite news articles to meet readability standards of elementary and middle schools, then demonstrate how we can develop new machine learning models to mimic the human editing process. </p>
					<p> I aim to answer four research questions: (1) How to create a parallel corpus for training neural text generation models? (2) How to design neural generation models with better controllability? (3) How to automatically evaluate system generated text outputs? (4) How to estimate the readability at the word- and phrase-level more reliably? </p>
					<p> On the high-level, we designed a neural Conditional Random Fields model to automatically align sentences between the complex and simplified articles, and consequently, created two large text simplification corpora (Newsela-Auto and Wiki-Auto). We also proposed a novel hybrid approach that leverages linguistically motivated rules for splitting and deletion, and couples with a neural paraphrasing model to produce varied rewriting styles. SARI, a tunable automatic evaluation metric, has been used for system comparison in addition to human evaluation. As for readability assessment, we improved the state-of-the-art by using a pairwise neural ranking model in conjunction with a manually rated word-complexity lexicon. </p>
				<p><b>Bio:</b> Wei Xu is an assistant professor in the School of Interactive Computing at the Georgia Institute of Technology. Before joining Georgia Tech, she was an assistant professor at Ohio State University since 2016. Xuâ€™s research interests are in natural language processing, machine learning, and social media. Her recent work focuses on text generation, semantics, information extraction, and reading assistive technology. She has received the NSF CRII Award, Best Paper Award at COLING, CrowdFlower AI for Everyone Award, and Criteo Faculty Research Award.</p>
				</div>
				<p><b> Slides: </b><a href="https://cocoxu.github.io/files/20201027_simplification_UPitt.pdf">Download </a></p>
			</div>
			</div>

			<hr>

			<div class="row">
			<div class="col-md-12 text-left">
				<div class="speaker-pic" style="display: inline-block">
					<img src="img/zhouyu.png">
				</div>
				<div>
				<h3> Zhou Yu </h3>
				<p><b> University of California, Davis</b></p>
				<p><b> Time:</b> 11/10/2020, Tuesday from 3 to 4 pm </p>
				<p><b> Place:</b> Zoom</p>
				<p><b> Title:</b> Personalized Persuasive Dialog Systems </p>
				<p><b> Topic:</b> Dialogue Systems </p>
				<p><b>Abstract:</b> Dialog systems such as Alexa and Siri are everywhere in our lives. They can complete tasks such as booking flights, making restaurant reservations and training people for interviews. These systems are passively follow-along human needs.  What if the dialog systems have a different goal than users. We introduce dialog systems that can persuade users to donate to charities. We further improve the dialog model's coherence by tracking both semantic actions and conversational strategies from dialog history using finite-state transducers. Finally, we analyze some ethical concerns and human factors in deploying personalized persuasive dialog systems. </p>
				<p><b>Bio:</b> Zhou Yu is an Assistant Professor at the UC Davis Computer Science Department. Zhou will join the CS department at Columbia University in Jan 2021 as an Assistant Professor. She obtained her Ph.D. from Carnegie Mellon University in 2017.  Zhou has built various dialog systems that have a real impact, such as a job interview training system, a depression screening system, and a second language learning system. Her research interest includes dialog systems, language understanding and generation, vision and language, human-computer interaction, and social robots. Zhou received an ACL 2019 best paper nomination, featured in Forbes 2018 30 under 30 in Science, and won the 2018 Amazon Alexa Prize. </p>
				</div>
			</div>
			</div>

			<hr>



			<!---
			<div class="col-md-3 text-center">
				<span class="icons c4">
				<i class="fa fa-globe"></i></span>
				<div class="box-area">
				<h3>User Experiance</h3>
				<p>Nothing</p>
				</div>
			</div>
			-->

		</div></div>
		<!--</div>-->


	</div>
	</section>

<div class="container2">

<form action="mailto:pittnlpseminar@list.pitt.edu" enctype="text/plain" method="POST">

  <div class ="email-box">
		<i class="fa fa-envelope" > </i>
		<input class="tbox" type="email" name="email" value="" placeholder="Enter your e-mail" required>
		<button class="btn" type="submit"  name="button"> Subscribe </button>
  </div>
 </form >
 </div>

	<div id="sub-footer">
		<div class="container">
			<div class="row">
				<div class="col-lg-6">
					<div class="copyright">
						<p>
							<span>&copy; All rights reserved </span>
						</p>
					</div>
				</div>
				<div class="col-lg-6">
					<ul class="social-network">
						<!--
						<li><a href="#" data-placement="top" title="Facebook"><i class="fa fa-facebook"></i></a></li>
						<li><a href="#" data-placement="top" title="Twitter"><i class="fa fa-twitter"></i></a></li>
						<li><a href="#" data-placement="top" title="Linkedin"><i class="fa fa-linkedin"></i></a></li>
						<li><a href="#" data-placement="top" title="Pinterest"><i class="fa fa-pinterest"></i></a></li>
						<li><a href="#" data-placement="top" title="Google plus"><i class="fa fa-google-plus"></i></a></li>
						-->
					</ul>
				</div>
			</div>
		</div>
	</div>
	</footer>
</div>

<!-- Something else -->
<a href="#" class="scrollup"><i class="fa fa-angle-up active"></i></a>
<!-- javascript
    ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="js/jquery.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.fancybox.pack.js"></script>
<script src="js/jquery.fancybox-media.js"></script>
<script src="js/portfolio/jquery.quicksand.js"></script>
<script src="js/portfolio/setting.js"></script>
<script src="js/jquery.flexslider.js"></script>
<script src="js/animate.js"></script>
<script src="js/custom.js"></script>
<script src="js/owl-carousel/owl.carousel.js"></script>
</body>
</html>
